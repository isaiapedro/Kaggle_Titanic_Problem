# Titanic Problem on Kaggle.com!
### (Predictive Model for Discrete Data)

## Contents

- [Introduction](#introduction)
- [Data Overview](#data-overview)
- [Conclusion](#conclusion)

## Introduction

This repository was made to solve the *Titanic Problem* on [Kaggle.com](https://www.kaggle.com/c/titanic).

<br/>

**A brief explanation of the problem:**

> The competition is simple: use machine learning to create a model that predicts which passengers survived the Titanic shipwreck.

<br/>

This work was a collaboration between me and @descarteslover and the objective was to complete the challenge with the best precision possible and take a first hands-on look into ML models and Kaggle competitions.

## Data Overview

First, we looked at the data that was given by the .csv files “Train” and “Test”.

Index | PassengerId | Survived |	Pclass |	Name |	Sex |	Age | SibSp | Parch | Ticket | Fare |	Cabin | Embarked
--- | --- | --- | --- |--- |--- |--- |--- |--- |--- |--- |--- | ---
0 | 1 | 0.0 | 3 | Braund, Mr. Owen Harris | male | 22.0 | 1 | 0 | A/5 | 21171 | 7.2500 | NaN | S

<br>
We noticed that there’s a lot of missing values and some data that could be grouped, specifically the parents and sibling’s columns.


### Conclusion

Thanks for reading up until here. We had a ton of fun doing this notebook and got a lot of useful insights on data manipulation and the implementation of some models, as Gradiant Boosting, Random Forest, Logistic Regression and Extra Tree.

If you want to see more Kaggle solutions, see the Flower Classification Problem or go to my github page. Feel free to reach me on [LinkedIn](https://www.linkedin.com/in/isaiapedro/) or my [Webpage](https://github.com/isaiapedro/Portfolio-Website).

Bye!
